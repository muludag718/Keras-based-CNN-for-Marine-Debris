{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0kFrVCl9N93"
      },
      "outputs": [],
      "source": [
        "class TrainModel():\n",
        "    def Model(self,channel,size):\n",
        "        from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "        from keras.models import Sequential\n",
        "        from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "        model = Sequential()\n",
        "        model.add(Convolution2D(32, (3, 3),\n",
        "                                activation='relu',\n",
        "                                input_shape=(channel, size, size),\n",
        "                                data_format='channels_first'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(Convolution2D(64, kernel_size=(3, 3)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(128))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Dense(10))\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(Activation('softmax'))\n",
        "        model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer='adam',\n",
        "                      metrics=[\"binary_accuracy\"])\n",
        "        return model\n",
        "    def GetDatas(self,listimg,listlabel,num_class):\n",
        "        import numpy as np\n",
        "        from keras.utils import np_utils\n",
        "        from sklearn.utils import shuffle\n",
        "        img_data = np.array(listimg)\n",
        "        img_data = img_data.astype('float32')\n",
        "        img_data /= 255\n",
        "        labels = np.array(listlabel)\n",
        "        Y = np_utils.to_categorical(labels, num_class)\n",
        "        x, y = shuffle(img_data, Y, random_state=30)\n",
        "        return x,y\n",
        "\n",
        "    def MyModel(self,imgdata, labeldata, size=28, channel=1, batchsize=200, \n",
        "                epochs=15, split=0.2, num_class=10):\n",
        "        import numpy as np\n",
        "        from sklearn.model_selection import train_test_split\n",
        "        x,y=self.GetDatas(imgdata,labeldata,num_class)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=split,random_state=6)\n",
        "        model=self.Model(channel,size)\n",
        "        X_train = X_train.reshape(-1, channel, size, size)\n",
        "        X_test = X_test.reshape(-1, channel, size, size)\n",
        "        hist = model.fit(X_train,y_train,\n",
        "                         batch_size=batchsize,\n",
        "                         epochs=epochs,\n",
        "                         verbose=1,\n",
        "                         validation_data=(X_test, y_test))\n",
        "        return model, hist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getDatas(size,channel=1,filter=False):\n",
        "  import os\n",
        "  import cv2\n",
        "  import numpy as np\n",
        "  from tqdm import tqdm\n",
        "  KATEGORILER = [\"bottle\",\"can\",\"chain\",\"drink-carton\",\"hook\",\"propeller\",\"shampoo-bottle\",\"standing-bottle\",\"tire\",\"valve\"]\n",
        "  DIR = \"marine-debris-watertank-release/class-image-crops\"\n",
        "  imgdata = []\n",
        "  labeldata=[]\n",
        "  for kategori in KATEGORILER:\n",
        "    klasor_adresi = os.path.join(DIR,kategori)\n",
        "    label = KATEGORILER.index(kategori)\n",
        "    for resim_adi in tqdm(os.listdir(klasor_adresi)):\n",
        "      resim_adresi = os.path.join(klasor_adresi,resim_adi)\n",
        "      resim = cv2.imread(resim_adresi)\n",
        "      if(resim is None):\n",
        "       print(\"Hata\")\n",
        "      else:\n",
        "       resim = cv2.resize(resim,(size,size))\n",
        "       if(channel==1):\n",
        "         resim = cv2.cvtColor(resim, cv2.COLOR_BGR2GRAY)\n",
        "       if(filter):\n",
        "         term = np.zeros((120, 120), dtype=np.uint8)\n",
        "         term = cv2.normalize(resim, term, 0, 255, cv2.NORM_MINMAX)\n",
        "         term = np.uint8(term)\n",
        "         resim = cv2.applyColorMap(term, cv2.COLORMAP_JET)\n",
        "       imgdata.append(resim)\n",
        "       labeldata.append(label)\n",
        "  return imgdata,labeldata"
      ],
      "metadata": {
        "id": "eE_cvKI_AOdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def modelsave(smodel,path):\n",
        "  from keras.models import save_model\n",
        "  smodel.save(path)\n",
        "def modelhistsave(hist,path):\n",
        "  import pandas as pd\n",
        "  if (\".csv\" in path):pass\n",
        "  else:path+=\".csv\"\n",
        "  df=pd.DataFrame(hist).to_csv(path)\n",
        "def loadmodelhist(path):\n",
        "  import pandas as pd\n",
        "  return pd.read_csv(path)\n",
        "def loadmodel(path):\n",
        "  from keras.models import load_model\n",
        "  return load_model(path)"
      ],
      "metadata": {
        "id": "6E_mj-eTAVGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_adres = \"/content/drive/MyDrive/Data/dataimg.zip\"\n",
        "!cp \"{zip_adres}\" .\n",
        "!unzip -q dataimg.zip\n",
        "!rm dataimg.zip"
      ],
      "metadata": {
        "id": "7GciQmMcAaiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_adres = \"/content/drive/MyDrive/Data/YeniData.zip\"\n",
        "!cp \"{zip_adres}\" .\n",
        "!unzip -q YeniData.zip\n",
        "!rm YeniData.zip"
      ],
      "metadata": {
        "id": "EyjFNePtFIx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r YeniData1.zip YeniDatalar1"
      ],
      "metadata": {
        "id": "Gd88oKNC8R5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp YeniData1.zip \"/content/drive/MyDrive/Data/\""
      ],
      "metadata": {
        "id": "yk-1lpWM80To"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def savetext(path,size,data):\n",
        "    a = [\"bottle\", \"can\", \"chain\", \"drink-carton\", \"hook\", \"propeller\", \"shampoo-bottle\", \"standing-bottle\", \"tire\",\n",
        "         \"valve\"]\n",
        "    datasizes = [449, 367, 226, 349, 133, 137, 99, 65, 331, 208]\n",
        "    top = 0\n",
        "    top2 = 0\n",
        "    text = \"\"\n",
        "    listeleme=[]\n",
        "    import pandas as pd\n",
        "    df_train = pd.DataFrame()\n",
        "    for index, item in enumerate(datasizes):\n",
        "        txt = f\"{a[index]} yüzde %{(data[index][index] / item) * 100}\"\n",
        "        df_train[a[index]]=[(data[index][index] / item) * 100];\n",
        "        print(txt)\n",
        "        top += data[index][index]\n",
        "        top2 += item\n",
        "        text += txt + \"\\n\"\n",
        "    text += f\"Genel Yüzde %{(top / top2) * 100}\"\n",
        "    df_train[\"Genel Yüzde\"]=[(top / top2) * 100]\n",
        "    df_train[\"Genel Yüzde\"]= [100]\n",
        "    df_train.to_csv(f\"{path}yüzdelikler{size}X{size}.csv\")\n",
        "    print(f\"Genel Yüzde %{(top / top2) * 100}\")\n",
        "    with open(path+f'output{size}X{size}.txt', 'w') as f:\n",
        "        f.write(text)\n",
        "        f.close()"
      ],
      "metadata": {
        "id": "EJ6eH1itOpZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Test3(test_image,label,tmodel,channel=1,size=28):\n",
        "  import cv2\n",
        "  from matplotlib import pyplot\n",
        "  import numpy as np\n",
        "  sinif=np.zeros((11, 11)).astype(int)\n",
        "  #test_image=cv2.resize(test_image,(size,size))\n",
        "  test_image = np.array(test_image)\n",
        "  test_image = test_image.astype('float32')\n",
        "  test_image /= 255\n",
        "  test_image = test_image.reshape(-1, channel ,size ,size)\n",
        "  f=(tmodel.predict(test_image) > 0.5).astype(\"int32\").tolist()\n",
        "  liste=[]\n",
        "  for ff in f:\n",
        "    deger=0\n",
        "    for ind,item in enumerate(ff):\n",
        "      deger+=(ind+1)*item\n",
        "    liste.append(deger)\n",
        "  for ind,list in enumerate(liste):\n",
        "    if(list==0):\n",
        "      sinif[label[ind],10]+=1\n",
        "      sinif[10,label[ind]]+=1\n",
        "    else:\n",
        "       sinif[label[ind],list-1]+=1\n",
        "  return sinif;"
      ],
      "metadata": {
        "id": "DJDDThYLcRU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mu(size,channel,batchsize,filtre=False):\n",
        "    images, labels = getDatas(size, channel,filter=filtre)\n",
        "    trainmodel = TrainModel()\n",
        "    model, hist = trainmodel.MyModel(images, labels, size, channel, batchsize)\n",
        "    ind = Test3(images, labels, model, channel, size)\n",
        "    f=\"3Channel\"\n",
        "    if filtre:\n",
        "      f=\"3FChannel\"\n",
        "    path = f\"YeniDatalar1/{f}/{batchsize}BatchSize/Size{size}X{size}/\"\n",
        "    import pandas as pd\n",
        "    df_train = pd.DataFrame()\n",
        "    a = [\"bottle\", \"can\", \"chain\", \"drink-carton\", \"hook\", \"propeller\", \"shampoo-bottle\", \"standing-bottle\", \"tire\",\n",
        "         \"valve\", \"None\"]\n",
        "    for i in range(11):\n",
        "        df_train[a[i]] = ind[i]\n",
        "    modelsave(model, f\"{path}{1}channel{size}X{size}.h5\")\n",
        "    df_train.to_csv(f\"{path}output{size}X{size}.csv\")\n",
        "    df1=pd.DataFrame(hist.history).to_csv(f\"{path}hist{size}X{size}.csv\")\n",
        "    savetext(path, size,ind)\n",
        "\n",
        "#channel=3\n",
        "#filtre=True\n",
        "#sizes=[16,28,32,64,92]\n",
        "#batchsizes=[15,25,50,75,100,150,200,300,400,500]\n",
        "\n",
        "#for batchsize in batchsizes:\n",
        "#  for size in sizes:\n",
        "#    mu(size,channel,batchsize)\n",
        "#for size in sizes:\n",
        "   # mu(size,1,15)"
      ],
      "metadata": {
        "id": "Z1KeFLDyNzP4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
